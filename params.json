{
  "name": "Stein Discrepancy",
  "tagline": "A practical tool for quantifying how well a sample approximates a target distribution",
  "body": "# SteinDiscrepancy.jl\r\n\r\n## What is this so-called Stein discrepancy?\r\n\r\nTo improve the efficiency of Monte Carlo estimation, practitioners are\r\nturning to biased Markov chain Monte Carlo procedures that trade off\r\nasymptotic exactness for computational speed. The reasoning is sound: a\r\nreduction in variance due to more rapid sampling can outweigh the bias\r\nintroduced. However, the inexactness creates new challenges for sampler and\r\nparameter selection, since standard measures of sample quality like\r\neffective sample size do not account for asymptotic bias. To address these\r\nchallenges, we introduce a new computable quality measure that quantifies\r\nthe maximum discrepancy between sample and target expectations over a large\r\nclass of test functions. This measure is what we are calling the\r\nStein discrepancy.\r\n\r\nFor a more detailed explanation, take a peek at the latest paper:\r\n\r\n[Measuring Sample Quality with Diffusions](https://arxiv.org/pdf/1611.06972v1.pdf).\r\n\r\nThis builds on previous work from\r\n\r\n[Measuring Sample Quality with Stein's Method](http://arxiv.org/abs/1506.03039)\r\n\r\nand its companion paper\r\n\r\n[Multivariate Stein Factors for a Class of Strongly Log-concave\r\nDistributions](http://arxiv.org/abs/1512.07392).\r\n\r\nThese latter two papers are a more gentle introduction describing how the\r\nStein discrepancy bounds standard probability metrics like the\r\n[L1-Wasserstein distance](https://en.wikipedia.org/wiki/Wasserstein_metric).\r\n\r\n## So how do I use it?\r\n\r\nThis software has been tested on Julia v0.4.5. Computing the Stein\r\ndiscrepancy requires solving a linear program (LP), and thus you'll need\r\nsome kind of LP solver installed to use this software. We use JuMP ([Julia\r\nfor Mathematical Programming](https://jump.readthedocs.org/en/latest/)) to\r\ninterface with these solvers; any of the supported JuMP LP solvers with do\r\njust fine.\r\n\r\nAssuming you have an LP solver installed, computing our measure is easy.\r\nFirst, clone this repo [or download it as a tarbell] in a directory of your\r\nchoosing. Next, you must have a target distribution in mind.  We represent\r\neach target distribution as a class (specifically, a subclass of a\r\n`SteinDistribution`) and encode all relevant information about the target\r\n(like the gradient of its log density) in that class. Various examples of\r\ntarget distributions can be found in the src/distributions. Feel free to add\r\nyour own!\r\n\r\nOnce you have this target in hand, the rest is easy. Here's a quick example\r\nthat you can run from the base directory (the parent directory of\r\nsrc). After you fire up julia from the command line, the following commands\r\nwill compute the Langevin Stein discrepancy for a bivariate uniform sample:\r\n\r\n```\r\n# set up source paths, and compile C++ code\r\ninclude(\"src/startup.jl\")\r\n# do the necessary imports\r\nusing SteinDistributions: SteinUniform\r\nusing SteinDiscrepancy: stein_discrepancy\r\n# creates a uniform distribution on [0,1]^2\r\ntarget = SteinUniform(2)\r\n# generates 100 points\r\nX = rand(target, 100)\r\n# can be a string or a JuMP solver\r\nsolver = \"clp\"\r\nresult = stein_discrepancy(points=X, target=target, solver=solver)\r\ndiscrepancy = vec(result.objective_value)\r\n```\r\n\r\nThe variable `discrepancy` here will encode the Stein discrepancy along each\r\ndimension. The final discrepancy is just the sum of this vector.\r\n\r\n## Summary of the Code\r\n\r\nAll code is available in the src directory of the repo. Many examples\r\ncomputing the stein_discrepancy are in the src/experiments directory. Tthe\r\nexperiment multimodal_gmm_langevin_floor is a good first one to examine. To\r\nsee an example that goes beyond the Langevin Stein discrepancy, see the\r\nexperiment compare-hyperparameters-multivariatetpseudohuber.\r\n\r\nMake sure to include startup.jl so all the paths are properly set up.\r\n(to do this, after opening the julia REPL, enter `include(\"src/startup.jl\")`\r\nat the command prompt)\r\n\r\n### Contents of src\r\n\r\n* startup.jl - Adds project module locations to LOAD_PATH\r\n* discrepancy - Code for computing Stein discrepancy\r\n* distributions - Types representing probability distributions\r\n* experiments - Code for running experiments\r\n* samplers - Code implementing the samplers of study\r\n* visualization - R scripts to create visualizations for the results\r\n\r\n### Conventions\r\n\r\n* Use lowercase file names (with underscores if needed for clarity) for scripts\r\n* Use camel case with initial capital letter for defining types and modules\r\n* Use lowercase (with underscores if needed for clarity) for variables and\r\n  functions (unless there are other prevailing conventions like X representing\r\n    a data matrix)\r\n\r\n### Compiling Code in discrepancy/spanner directory\r\n\r\nOur C++ code should be compiled when startup.jl is first invoked. However,\r\nif this doesn't work for some reason, you can issue the following\r\ncommands to compile the code in discrepancy/spanner:\r\n\r\n```\r\ncd discrepancy/spanner\r\nmake\r\nmake clean\r\n```\r\n\r\nThe last step isn't necessary, but it will remove some superfluous\r\nfiles. If you want to kill everything made in the build process, just run\r\n\r\n```\r\nmake distclean\r\n```",
  "google": "",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}